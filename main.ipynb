{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "dataframe = pd.read_csv('data.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to clean the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(dataframe = None, message = None):\n",
    "    if dataframe is not None:\n",
    "        dataframe['Processed'] = None\n",
    "        for i in range(len(dataframe['Message'].values)):\n",
    "            # lowering the texts\n",
    "            temp_text = dataframe['Message'][i].lower()\n",
    "\n",
    "            # removing punctuations \n",
    "            for letter in temp_text:\n",
    "                if letter in punctuation:\n",
    "                    temp_text = temp_text.replace(letter,'')\n",
    "\n",
    "            # stop words\n",
    "            for word in temp_text.split():\n",
    "                if word in stopwords.words('english'):\n",
    "                    temp_text = temp_text.replace(word,'')\n",
    "                    temp_text = ' '.join(temp_text.split())\n",
    "\n",
    "            # stemming\n",
    "            stemmer = SnowballStemmer('english')\n",
    "            result = ''\n",
    "            for word in temp_text.split():\n",
    "                result += stemmer.stem(word)\n",
    "                result += ' '\n",
    "\n",
    "            dataframe['Processed'][i] = result.split()\n",
    "        return dataframe\n",
    "    \n",
    "    else:\n",
    "        temp_text = message.lower()\n",
    "\n",
    "        # removing punctuations\n",
    "        for letter in temp_text:\n",
    "            if letter in punctuation:\n",
    "                temp_text = temp_text.replace(letter,'')\n",
    "\n",
    "        # stop words\n",
    "        for word in temp_text.split():\n",
    "            if word in stopwords.words('english'):\n",
    "                temp_text = temp_text.replace(word,'')\n",
    "                temp_text = ' '.join(temp_text.split())\n",
    "\n",
    "        # stemming\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        result = ''\n",
    "        for word in temp_text.split():\n",
    "            result += stemmer.stem(word)\n",
    "            result += ' '\n",
    "\n",
    "        \n",
    "        return result.split()\n",
    "\n",
    "\n",
    "dataframe = process_message(dataframe = dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, pot, crazi, avail, bugi, n, great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, w, f, cup, fl, tk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, thnk, goe, usf, lves, around, re, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           Processed  \n",
       "0  [go, jurong, pot, crazi, avail, bugi, n, great...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, w, f, cup, fl, tk...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, dont, thnk, goe, usf, lves, around, re, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Spam and Ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Spam: 747\n",
      "Number of Ham: 4825\n"
     ]
    }
   ],
   "source": [
    "print('Number of Spam: ' + str(dataframe[dataframe['Category']=='spam'].shape[0]))\n",
    "print('Number of Ham: ' + str(dataframe[dataframe['Category']=='ham'].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating freqs dictionary that contains the (word,label) as key and its frequency as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = {}\n",
    "for i in range(dataframe.shape[0]):\n",
    "    if dataframe['Category'][i] == 'spam':\n",
    "        for word in dataframe['Processed'][i]:\n",
    "            if (word,0) in freqs.keys():\n",
    "                freqs[(word,0)] += 1\n",
    "            else:\n",
    "                freqs[(word,0)] = 1\n",
    "    else:\n",
    "        for word in dataframe['Processed'][i]:\n",
    "            if (word,1) in freqs.keys():\n",
    "                freqs[(word,1)] += 1\n",
    "            else:\n",
    "                freqs[(word,1)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe['Message'], dataframe['Category'],random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X_train, y_train, freqs):\n",
    "\n",
    "    log_prior = 0\n",
    "    log_likelihood = {}\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    N_spam = N_ham = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if spam\n",
    "        if pair[1] == 0:\n",
    "            N_spam += freqs[pair]\n",
    "\n",
    "        else:\n",
    "            N_ham += freqs[pair]\n",
    "\n",
    "    D = len(y_train)\n",
    "    D_ham = len(y_train[y_train=='ham'])\n",
    "    D_spam = len(y_train[y_train=='spam'])\n",
    "\n",
    "    log_prior = np.log(D_ham/D) - np.log(D_spam/D)\n",
    "\n",
    "    for word in vocab:\n",
    "        freqs_ham = freqs.get((word,1),0)\n",
    "        freqs_spam = freqs.get((word,0),0)\n",
    "\n",
    "        p_w_ham = (freqs_ham + 1) / (N_ham + V)\n",
    "        p_w_spam = (freqs_spam + 1) / (N_spam + V)\n",
    "\n",
    "        log_likelihood[word] = np.log(p_w_ham/p_w_spam)\n",
    "    \n",
    "    return log_prior , log_likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8623995161821434\n"
     ]
    }
   ],
   "source": [
    "log_prior, log_likelihood = train_naive_bayes(X_train,y_train, freqs)\n",
    "print(log_prior)\n",
    "# print(log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(message, log_prior, log_likelihood):\n",
    "    \n",
    "    tokens = process_message(message=message)\n",
    "    p=0\n",
    "\n",
    "    # log_prior\n",
    "    p += log_prior\n",
    "\n",
    "    for word in tokens:\n",
    "        p += log_likelihood.get(word,0)\n",
    "    \n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.145239039883805\n"
     ]
    }
   ],
   "source": [
    "p = predict_naive_bayes('I would like to give you a free vacation trip', log_prior, log_likelihood)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(X_test, y_test, log_prior, log_likelihood):\n",
    "    accuracy = 0\n",
    "    y_hat = []\n",
    "    y = []\n",
    "    for i in y_test.values:\n",
    "        if i == 'ham':\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    for doc in X_test:\n",
    "        if predict_naive_bayes(doc,log_prior= log_prior, log_likelihood= log_likelihood) >0:\n",
    "            # not a spam (ham)\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            # spam\n",
    "            y_hat.append(0)\n",
    "    \n",
    "    error = np.mean(np.abs(np.array(y_hat)-np.array(y)))\n",
    "\n",
    "    return 1-error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is: 0.989247311827957\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the model is: ' + str(test_naive_bayes(X_test,y_test,log_prior,log_likelihood)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5addf786bcd861d1ce5006f23111f8cbb206731e5b61b0a5632ba9e0252558a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
